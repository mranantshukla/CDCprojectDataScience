{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multimodal House Price Valuation — Modeling & Fusion\n",
        "\n",
        "This notebook implements and compares **tabular-only**, **image-only**, and **multimodal fusion** models for predicting house prices.\n",
        "\n",
        "Key goals:\n",
        "- Establish strong **tabular baselines** (linear and tree-based).\n",
        "- Use a **pretrained ResNet** as an image feature extractor (frozen backbone, CPU-friendly).\n",
        "- Compare **late fusion** and **feature-level fusion** strategies.\n",
        "- Evaluate whether satellite imagery provides **robust, economically meaningful gains** over tabular features alone.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data and Problem Setup\n",
        "\n",
        "We use the following datasets:\n",
        "\n",
        "- `data/raw/train.csv` (or `train.csv` in project root): training data with observed prices.\n",
        "- `data/raw/test.xlsx` (or `test.xlsx` in project root): features-only test set for blind prediction.\n",
        "- `data/processed/train.parquet`, `data/processed/val.parquet`: **leakage-aware splits** created in `preprocessing.ipynb` using spatial grouping.\n",
        "- `data/satellite/image_metadata.csv`: mapping from property IDs to Sentinel tiles (generated by `data_fetcher.py`).\n",
        "\n",
        "Our target is typically `price`, modelled on the log scale (`log_price`) for numerical stability. We always compare models on the **original price scale** via RMSE and R².\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "PROJECT_ROOT = Path(\"..\").resolve()\n",
        "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
        "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
        "SATELLITE_DIR = PROJECT_ROOT / \"data\" / \"satellite\"\n",
        "EMBEDDINGS_DIR = PROJECT_ROOT / \"data\" / \"embeddings\"\n",
        "REPORTS_DIR = PROJECT_ROOT / \"reports\"\n",
        "\n",
        "for d in [EMBEDDINGS_DIR, REPORTS_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Load processed splits (created in preprocessing.ipynb)\n",
        "train_path = PROCESSED_DIR / \"train.parquet\"\n",
        "val_path = PROCESSED_DIR / \"val.parquet\"\n",
        "\n",
        "if not train_path.exists() or not val_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Expected processed splits at {train_path} and {val_path}. \"\n",
        "        \"Run preprocessing.ipynb first to generate leakage-aware splits.\"\n",
        "    )\n",
        "\n",
        "train_df = pd.read_parquet(train_path)\n",
        "val_df = pd.read_parquet(val_path)\n",
        "\n",
        "print(\"Train split:\", train_df.shape)\n",
        "print(\"Val split:\", val_df.shape)\n",
        "\n",
        "# Infer key columns (must match preprocessing)\n",
        "from collections import Counter\n",
        "\n",
        "cols = train_df.columns\n",
        "\n",
        "TARGET_COL = \"log_price\" if \"log_price\" in cols else \"price\"\n",
        "ID_COL = \"id\" if \"id\" in cols else \"Id\" if \"Id\" in cols else None\n",
        "LAT_COL = \"lat\" if \"lat\" in cols else \"latitude\" if \"latitude\" in cols else None\n",
        "LON_COL = \"long\" if \"long\" in cols else \"lon\" if \"lon\" in cols else \"longitude\" if \"longitude\" in cols else None\n",
        "\n",
        "if ID_COL is None:\n",
        "    raise ValueError(\"Could not infer ID column in processed data.\")\n",
        "\n",
        "print(\"TARGET_COL =\", TARGET_COL)\n",
        "print(\"ID_COL =\", ID_COL)\n",
        "print(\"LAT_COL =\", LAT_COL)\n",
        "print(\"LON_COL =\", LON_COL)\n",
        "\n",
        "# If target is on log scale, keep a copy of original price if available\n",
        "if TARGET_COL == \"log_price\" and \"price\" in cols:\n",
        "    PRICE_COL = \"price\"\n",
        "else:\n",
        "    PRICE_COL = TARGET_COL\n",
        "\n",
        "print(\"PRICE_COL (for metrics) =\", PRICE_COL)\n",
        "\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build tabular feature matrix and baseline models\n",
        "\n",
        "# Separate target and features\n",
        "\n",
        "y_train = train_df[TARGET_COL].values\n",
        "X_train = train_df.drop(columns=[TARGET_COL])\n",
        "\n",
        "y_val = val_df[TARGET_COL].values\n",
        "X_val = val_df.drop(columns=[TARGET_COL])\n",
        "\n",
        "# Identify numeric and categorical columns\n",
        "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if ID_COL in numeric_features:\n",
        "    numeric_features.remove(ID_COL)\n",
        "\n",
        "categorical_features = [\n",
        "    c for c in X_train.columns if c not in numeric_features and c != ID_COL\n",
        "]\n",
        "\n",
        "print(\"Numeric features (tabular):\", len(numeric_features))\n",
        "print(\"Categorical features (tabular):\", len(categorical_features))\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\n",
        "            \"onehot\",\n",
        "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Linear baseline (on log-price if available)\n",
        "lin_model = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"regressor\", Ridge(alpha=1.0)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "lin_model.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred_lin = lin_model.predict(X_val)\n",
        "\n",
        "if TARGET_COL == \"log_price\" and PRICE_COL in val_df.columns:\n",
        "    # Evaluate on price scale\n",
        "    y_val_price = val_df[PRICE_COL].values\n",
        "    y_val_price_pred = np.expm1(y_val_pred_lin)\n",
        "    baseline_rmse = rmse(y_val_price, y_val_price_pred)\n",
        "else:\n",
        "    y_val_price = y_val\n",
        "    y_val_price_pred = y_val_pred_lin\n",
        "    baseline_rmse = rmse(y_val_price, y_val_price_pred)\n",
        "\n",
        "baseline_r2 = r2_score(y_val_price, y_val_price_pred)\n",
        "\n",
        "print(f\"Linear baseline RMSE (price scale): {baseline_rmse:,.2f}\")\n",
        "print(f\"Linear baseline R^2: {baseline_r2:.3f}\")\n",
        "\n",
        "# Tree-based baseline (Random Forest)\n",
        "rf_model = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\n",
        "            \"regressor\",\n",
        "            RandomForestRegressor(\n",
        "                n_estimators=200,\n",
        "                max_depth=None,\n",
        "                min_samples_leaf=2,\n",
        "                n_jobs=-1,\n",
        "                random_state=42,\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred_rf = rf_model.predict(X_val)\n",
        "\n",
        "if TARGET_COL == \"log_price\" and PRICE_COL in val_df.columns:\n",
        "    y_val_price_pred_rf = np.expm1(y_val_pred_rf)\n",
        "else:\n",
        "    y_val_price_pred_rf = y_val_pred_rf\n",
        "\n",
        "rf_rmse = rmse(y_val_price, y_val_price_pred_rf)\n",
        "rf_r2 = r2_score(y_val_price, y_val_price_pred_rf)\n",
        "\n",
        "print(f\"Random Forest RMSE (price scale): {rf_rmse:,.2f}\")\n",
        "print(f\"Random Forest R^2: {rf_r2:.3f}\")\n",
        "\n",
        "TABULAR_BASELINE_RMSE = min(baseline_rmse, rf_rmse)\n",
        "TABULAR_BASELINE_R2 = max(baseline_r2, rf_r2)\n",
        "\n",
        "print(\"Best tabular baseline RMSE:\", TABULAR_BASELINE_RMSE)\n",
        "print(\"Best tabular baseline R^2:\", TABULAR_BASELINE_R2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CNN Feature Extraction with Pretrained ResNet\n",
        "\n",
        "We now treat the satellite imagery as a **feature extractor**, not a standalone classifier:\n",
        "\n",
        "- Use a pretrained **ResNet18** (or similar) from `torchvision.models`.\n",
        "- **Freeze** the convolutional backbone so we only reuse generic spatial filters.\n",
        "- Resize tiles to a standard input size (e.g., 224×224) and normalise using ImageNet statistics.\n",
        "- Extract **fixed 512-D embeddings** (after global average pooling) and cache them to `data/embeddings/`.\n",
        "\n",
        "These embeddings serve as image-derived features for both **image-only** and **multimodal** models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare image metadata and ResNet feature extractor\n",
        "\n",
        "meta_path = SATELLITE_DIR / \"image_metadata.csv\"\n",
        "if not meta_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"No satellite metadata found at {meta_path}. \"\n",
        "        \"Run data_fetcher.py first to download Sentinel tiles.\"\n",
        "    )\n",
        "\n",
        "meta_df = pd.read_csv(meta_path)\n",
        "meta_df = meta_df[meta_df[\"status\"].isin([\"ok\", \"cached\"])]\n",
        "\n",
        "# Align ID column naming\n",
        "if ID_COL != \"id\" and \"id\" in meta_df.columns:\n",
        "    meta_df = meta_df.rename(columns={\"id\": ID_COL})\n",
        "\n",
        "# Keep only rows with existing image files\n",
        "meta_df = meta_df[meta_df[\"image_path\"].apply(lambda p: Path(p).exists())]\n",
        "\n",
        "print(\"Usable satellite images:\", len(meta_df))\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "img_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225],\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "class SatelliteDataset(Dataset):\n",
        "    def __init__(self, df, id_col, target_col, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.id_col = id_col\n",
        "        self.target_col = target_col\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):  # noqa: D401\n",
        "        \"\"\"Number of available image samples.\"\"\"\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        target = float(row[self.target_col])\n",
        "        sample_id = row[self.id_col]\n",
        "        return img, target, sample_id\n",
        "\n",
        "\n",
        "# Load a pretrained ResNet18 and turn it into a pure feature extractor\n",
        "try:\n",
        "    resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "except AttributeError:\n",
        "    # Older torchvision versions\n",
        "    resnet = models.resnet18(pretrained=True)\n",
        "\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "feature_dim = resnet.fc.in_features\n",
        "resnet.fc = nn.Identity()  # outputs pooled features directly\n",
        "\n",
        "resnet.eval()\n",
        "resnet.to(device)\n",
        "\n",
        "\n",
        "def extract_resnet_embeddings(split_df, split_name, batch_size=32):\n",
        "    \"\"\"Compute (or load) ResNet embeddings for a given split.\n",
        "\n",
        "    Returns a DataFrame with one row per property ID and columns:\n",
        "    - ID_COL\n",
        "    - img_emb_0, ..., img_emb_{feature_dim-1}\n",
        "    \"\"\"\n",
        "\n",
        "    out_path = EMBEDDINGS_DIR / f\"resnet18_{split_name}_embeddings.parquet\"\n",
        "    if out_path.exists():\n",
        "        print(f\"Loading cached embeddings from {out_path}\")\n",
        "        return pd.read_parquet(out_path)\n",
        "\n",
        "    merged = split_df[[ID_COL, TARGET_COL]].merge(\n",
        "        meta_df[[ID_COL, \"image_path\"]], on=ID_COL, how=\"inner\"\n",
        "    )\n",
        "\n",
        "    if merged.empty:\n",
        "        raise RuntimeError(\n",
        "            f\"No overlapping IDs between {split_name} split and satellite metadata.\"\n",
        "        )\n",
        "\n",
        "    dataset = SatelliteDataset(\n",
        "        merged[[ID_COL, \"image_path\", TARGET_COL]],\n",
        "        id_col=ID_COL,\n",
        "        target_col=TARGET_COL,\n",
        "        transform=img_transform,\n",
        "    )\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,  # safer on Windows / notebooks\n",
        "    )\n",
        "\n",
        "    all_embeddings = []\n",
        "    all_ids = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, _, ids in loader:\n",
        "            imgs = imgs.to(device)\n",
        "            feats = resnet(imgs)  # (B, feature_dim)\n",
        "            all_embeddings.append(feats.cpu().numpy())\n",
        "            # Convert tensor IDs to plain Python integers to keep parquet happy\n",
        "            all_ids.extend([int(i) for i in ids])\n",
        "\n",
        "    emb_array = np.concatenate(all_embeddings, axis=0)\n",
        "    emb_cols = [f\"img_emb_{i}\" for i in range(emb_array.shape[1])]\n",
        "    emb_df = pd.DataFrame(emb_array, columns=emb_cols)\n",
        "    emb_df[ID_COL] = all_ids\n",
        "\n",
        "    emb_df.to_parquet(out_path, index=False)\n",
        "    print(f\"Saved embeddings for {split_name} to {out_path}\")\n",
        "\n",
        "    return emb_df\n",
        "\n",
        "\n",
        "train_img_emb = extract_resnet_embeddings(train_df, split_name=\"train\", batch_size=32)\n",
        "val_img_emb = extract_resnet_embeddings(val_df, split_name=\"val\", batch_size=32)\n",
        "\n",
        "print(\"Train image embeddings:\", train_img_emb.shape)\n",
        "print(\"Val image embeddings:\", val_img_emb.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Strategy A — Late Fusion\n",
        "\n",
        "We now build **separate models** for tabular and image features, then combine them at the prediction level:\n",
        "\n",
        "1. **Tabular model**: best-performing baseline from above (linear or Random Forest).\n",
        "2. **Image-only model**: regression on ResNet embeddings (e.g., Random Forest).\n",
        "3. **Fusion model**: a simple linear combiner on top of tabular and image predictions.\n",
        "\n",
        "This lets us ask: *Given a strong tabular model, does adding image-based predictions materially improve RMSE/R² in a stable way?*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build image-only and late-fusion models\n",
        "\n",
        "# Join embeddings with tabular splits\n",
        "\n",
        "train_with_img = train_df.merge(train_img_emb, on=ID_COL, how=\"inner\")\n",
        "val_with_img = val_df.merge(val_img_emb, on=ID_COL, how=\"inner\")\n",
        "\n",
        "print(\"Train with image features:\", train_with_img.shape)\n",
        "print(\"Val with image features:\", val_with_img.shape)\n",
        "\n",
        "# Image-only features (embeddings only)\n",
        "emb_cols = [c for c in train_with_img.columns if c.startswith(\"img_emb_\")]\n",
        "\n",
        "X_train_img = train_with_img[emb_cols].values\n",
        "X_val_img = val_with_img[emb_cols].values\n",
        "\n",
        "y_train_img = train_with_img[TARGET_COL].values\n",
        "_y_val_img = val_with_img[TARGET_COL].values  # same as y_val but aligned subset\n",
        "\n",
        "img_rf = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,\n",
        "    min_samples_leaf=2,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "img_rf.fit(X_train_img, y_train_img)\n",
        "\n",
        "y_val_pred_img = img_rf.predict(X_val_img)\n",
        "\n",
        "if TARGET_COL == \"log_price\" and PRICE_COL in val_with_img.columns:\n",
        "    y_val_price_img = val_with_img[PRICE_COL].values\n",
        "    y_val_price_pred_img = np.expm1(y_val_pred_img)\n",
        "else:\n",
        "    y_val_price_img = _y_val_img\n",
        "    y_val_price_pred_img = y_val_pred_img\n",
        "\n",
        "img_rmse = rmse(y_val_price_img, y_val_price_pred_img)\n",
        "img_r2 = r2_score(y_val_price_img, y_val_price_pred_img)\n",
        "\n",
        "print(f\"Image-only RF RMSE (price scale): {img_rmse:,.2f}\")\n",
        "print(f\"Image-only RF R^2: {img_r2:.3f}\")\n",
        "\n",
        "# Align tabular baseline predictions to the subset with embeddings\n",
        "\n",
        "X_val_subset = val_df[val_df[ID_COL].isin(val_with_img[ID_COL])].copy()\n",
        "\n",
        "lin_val_subset_pred = lin_model.predict(X_val_subset)\n",
        "if TARGET_COL == \"log_price\" and PRICE_COL in val_df.columns:\n",
        "    tab_price_pred = np.expm1(lin_val_subset_pred)\n",
        "    tab_price_true = X_val_subset[PRICE_COL].values\n",
        "else:\n",
        "    tab_price_pred = lin_val_subset_pred\n",
        "    tab_price_true = X_val_subset[TARGET_COL].values\n",
        "\n",
        "# Match order with image subset\n",
        "fusion_df = val_with_img[[ID_COL]].merge(\n",
        "    pd.DataFrame(\n",
        "        {ID_COL: X_val_subset[ID_COL].values, \"tab_pred\": tab_price_pred,\n",
        "         \"tab_true\": tab_price_true}\n",
        "    ),\n",
        "    on=ID_COL,\n",
        "    how=\"inner\",\n",
        ")\n",
        "\n",
        "fusion_df = fusion_df.merge(\n",
        "    pd.DataFrame(\n",
        "        {\n",
        "            ID_COL: val_with_img[ID_COL].values,\n",
        "            \"img_pred\": y_val_price_pred_img,\n",
        "        }\n",
        "    ),\n",
        "    on=ID_COL,\n",
        "    how=\"inner\",\n",
        ")\n",
        "\n",
        "print(f\"Fusion evaluation on {len(fusion_df)} validation examples.\")\n",
        "\n",
        "# Simple linear combiner learned on validation (could also use cross-validation)\n",
        "\n",
        "fusion_X = fusion_df[[\"tab_pred\", \"img_pred\"]].values\n",
        "fusion_y = fusion_df[\"tab_true\"].values\n",
        "\n",
        "fusion_reg = LinearRegression()\n",
        "fusion_reg.fit(fusion_X, fusion_y)\n",
        "\n",
        "fusion_pred = fusion_reg.predict(fusion_X)\n",
        "\n",
        "fusion_rmse = rmse(fusion_y, fusion_pred)\n",
        "fusion_r2 = r2_score(fusion_y, fusion_pred)\n",
        "\n",
        "print(f\"Late fusion RMSE (price scale): {fusion_rmse:,.2f}\")\n",
        "print(f\"Late fusion R^2: {fusion_r2:.3f}\")\n",
        "\n",
        "improvement_vs_tab = 100.0 * (TABULAR_BASELINE_RMSE - fusion_rmse) / TABULAR_BASELINE_RMSE\n",
        "print(f\"% RMSE improvement over best tabular baseline: {improvement_vs_tab:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Strategy B — Feature-Level Fusion\n",
        "\n",
        "In feature-level fusion, we **concatenate** processed tabular features and CNN embeddings, then train a **single regression head**:\n",
        "\n",
        "- Tabular branch: standardised numeric features + one-hot encoded categoricals.\n",
        "- Image branch: fixed 512-D ResNet embeddings (already normalised).\n",
        "- Fusion model: a modest-capacity regressor (e.g., Random Forest or MLP) on top of the concatenated vector.\n",
        "\n",
        "This tests whether **jointly** using tabular and image features allows the model to exploit interactions that late fusion cannot capture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Construct feature-level fusion dataset\n",
        "\n",
        "# First, obtain preprocessed tabular design matrices from the trained preprocessor\n",
        "X_train_tab = preprocessor.fit_transform(X_train)\n",
        "X_val_tab = preprocessor.transform(X_val)\n",
        "\n",
        "print(\"Tabular feature matrix shapes:\", X_train_tab.shape, X_val_tab.shape)\n",
        "\n",
        "# Align rows with embeddings (inner join on ID)\n",
        "train_idx_map = {idx: i for i, idx in enumerate(train_df[ID_COL].values)}\n",
        "val_idx_map = {idx: i for i, idx in enumerate(val_df[ID_COL].values)}\n",
        "\n",
        "train_fusion_ids = np.intersect1d(train_df[ID_COL].values, train_img_emb[ID_COL].values)\n",
        "val_fusion_ids = np.intersect1d(val_df[ID_COL].values, val_img_emb[ID_COL].values)\n",
        "\n",
        "print(\"Train fusion IDs:\", len(train_fusion_ids))\n",
        "print(\"Val fusion IDs:\", len(val_fusion_ids))\n",
        "\n",
        "# Build aligned matrices\n",
        "\n",
        "def build_fusion_matrices(ids, df, idx_map, X_tab, emb_df):\n",
        "    tab_rows = []\n",
        "    img_rows = []\n",
        "    targets = []\n",
        "    for pid in ids:\n",
        "        tab_idx = idx_map[pid]\n",
        "        tab_rows.append(X_tab[tab_idx])\n",
        "        img_rows.append(emb_df.loc[emb_df[ID_COL] == pid, emb_cols].values[0])\n",
        "        targets.append(df.loc[df[ID_COL] == pid, TARGET_COL].values[0])\n",
        "    return (\n",
        "        np.vstack(tab_rows),\n",
        "        np.vstack(img_rows),\n",
        "        np.array(targets),\n",
        "    )\n",
        "\n",
        "X_train_tab_f, X_train_img_f, y_train_f = build_fusion_matrices(\n",
        "    train_fusion_ids, train_df, train_idx_map, X_train_tab, train_img_emb\n",
        ")\n",
        "X_val_tab_f, X_val_img_f, y_val_f = build_fusion_matrices(\n",
        "    val_fusion_ids, val_df, val_idx_map, X_val_tab, val_img_emb\n",
        ")\n",
        "\n",
        "X_train_fusion = np.hstack([X_train_tab_f, X_train_img_f])\n",
        "X_val_fusion = np.hstack([X_val_tab_f, X_val_img_f])\n",
        "\n",
        "print(\"Fusion feature matrices:\", X_train_fusion.shape, X_val_fusion.shape)\n",
        "\n",
        "# Train a modest-capacity Random Forest on fused features\n",
        "fusion_rf = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,\n",
        "    min_samples_leaf=2,\n",
        "    n_jobs=-1,\n",
        "    random_state=123,\n",
        ")\n",
        "\n",
        "fusion_rf.fit(X_train_fusion, y_train_f)\n",
        "\n",
        "fusion_val_pred = fusion_rf.predict(X_val_fusion)\n",
        "\n",
        "if TARGET_COL == \"log_price\" and PRICE_COL in val_df.columns:\n",
        "    # Use aligned price values for evaluation\n",
        "    val_price_aligned = []\n",
        "    for pid in val_fusion_ids:\n",
        "        val_price_aligned.append(val_df.loc[val_df[ID_COL] == pid, PRICE_COL].values[0])\n",
        "    val_price_aligned = np.array(val_price_aligned)\n",
        "    fusion_val_price_pred = np.expm1(fusion_val_pred)\n",
        "else:\n",
        "    val_price_aligned = y_val_f\n",
        "    fusion_val_price_pred = fusion_val_pred\n",
        "\n",
        "fusion_rmse_feat = rmse(val_price_aligned, fusion_val_price_pred)\n",
        "fusion_r2_feat = r2_score(val_price_aligned, fusion_val_price_pred)\n",
        "\n",
        "print(f\"Feature-level fusion RF RMSE (price scale): {fusion_rmse_feat:,.2f}\")\n",
        "print(f\"Feature-level fusion RF R^2: {fusion_r2_feat:.3f}\")\n",
        "\n",
        "improvement_vs_tab_feat = 100.0 * (TABULAR_BASELINE_RMSE - fusion_rmse_feat) / TABULAR_BASELINE_RMSE\n",
        "print(f\"% RMSE improvement over best tabular baseline: {improvement_vs_tab_feat:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Model Choice and Test-Set Predictions\n",
        "\n",
        "We now select the model that offers the **best trade-off** between:\n",
        "\n",
        "- Predictive performance (RMSE, R²) on the validation set.\n",
        "- Stability of improvements from imagery over tabular-only baselines.\n",
        "- Interpretability and complexity.\n",
        "\n",
        "For illustration, we assume the **feature-level fusion Random Forest** is chosen (you may override this choice after inspecting metrics), and use it to generate predictions for `test.xlsx`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load raw test features and generate predictions with the chosen model\n",
        "\n",
        "# Load test\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Support data/raw/test.xlsx, project-root test.xlsx, or Provided/test.xlsx\n",
        "\n",
        "PROVIDED_DIR = PROJECT_ROOT / \"Provided\"\n",
        "\n",
        "test_candidates = [\n",
        "    RAW_DIR / \"test.xlsx\",\n",
        "    PROJECT_ROOT / \"test.xlsx\",\n",
        "    PROVIDED_DIR / \"test.xlsx\",\n",
        "]\n",
        "for p in test_candidates:\n",
        "    if p.exists():\n",
        "        TEST_PATH = p\n",
        "        break\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Could not find test.xlsx in {test_candidates}.\")\n",
        "\n",
        "print(\"Using TEST_PATH =\", TEST_PATH)\n",
        "\n",
        "test_df_raw = pd.read_excel(TEST_PATH)\n",
        "\n",
        "# Ensure ID column exists\n",
        "if ID_COL not in test_df_raw.columns:\n",
        "    raise ValueError(f\"Expected ID column '{ID_COL}' in test data.\")\n",
        "\n",
        "# Apply same preprocessing as training\n",
        "X_test_tab = test_df_raw.drop(columns=[c for c in [TARGET_COL, \"log_price\", \"price\"] if c in test_df_raw.columns])\n",
        "\n",
        "# Align columns with training features\n",
        "missing_numeric = [c for c in numeric_features if c not in X_test_tab.columns]\n",
        "for c in missing_numeric:\n",
        "    X_test_tab[c] = np.nan\n",
        "\n",
        "missing_cats = [c for c in categorical_features if c not in X_test_tab.columns]\n",
        "for c in missing_cats:\n",
        "    X_test_tab[c] = \"missing\"\n",
        "\n",
        "X_test_tab = X_test_tab[numeric_features + categorical_features]\n",
        "\n",
        "X_test_tab_proc = preprocessor.transform(X_test_tab)\n",
        "\n",
        "# Join with image embeddings for test set (if available)\n",
        "\n",
        "# Build embeddings for test if not already computed\n",
        "try:\n",
        "    test_img_emb = extract_resnet_embeddings(test_df_raw.assign(**{TARGET_COL: np.nan}), split_name=\"test\", batch_size=32)\n",
        "except RuntimeError as e:\n",
        "    print(\"Warning: could not compute test embeddings:\", e)\n",
        "    test_img_emb = None\n",
        "\n",
        "if test_img_emb is not None:\n",
        "    # Align IDs\n",
        "    test_ids = test_df_raw[ID_COL].values\n",
        "    test_img_emb = test_img_emb[test_img_emb[ID_COL].isin(test_ids)]\n",
        "\n",
        "    # Map from ID to row index in tabular matrix\n",
        "    test_idx_map = {idx: i for i, idx in enumerate(test_ids)}\n",
        "\n",
        "    fusion_test_ids = np.intersect1d(test_ids, test_img_emb[ID_COL].values)\n",
        "\n",
        "    tab_rows = []\n",
        "    img_rows = []\n",
        "    out_ids = []\n",
        "    for pid in fusion_test_ids:\n",
        "        tab_idx = test_idx_map[pid]\n",
        "        tab_rows.append(X_test_tab_proc[tab_idx])\n",
        "        img_rows.append(test_img_emb.loc[test_img_emb[ID_COL] == pid, emb_cols].values[0])\n",
        "        out_ids.append(pid)\n",
        "\n",
        "    X_test_tab_f = np.vstack(tab_rows)\n",
        "    X_test_img_f = np.vstack(img_rows)\n",
        "    X_test_fusion = np.hstack([X_test_tab_f, X_test_img_f])\n",
        "\n",
        "    # Use feature-level fusion RF as the final model (adjust if you prefer a different model)\n",
        "    test_pred_log = fusion_rf.predict(X_test_fusion)\n",
        "    test_pred_price = np.expm1(test_pred_log) if TARGET_COL == \"log_price\" else test_pred_log\n",
        "\n",
        "    pred_df = pd.DataFrame(\n",
        "        {\n",
        "            ID_COL: out_ids,\n",
        "            \"actual_price\": np.nan,  # blind test; actuals unknown at prediction time\n",
        "            \"predicted_price\": test_pred_price,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    out_csv = REPORTS_DIR / \"predictions_test.csv\"\n",
        "    pred_df.to_csv(out_csv, index=False)\n",
        "    print(\"Saved test predictions to\", out_csv)\n",
        "else:\n",
        "    print(\"No image embeddings for test set; consider falling back to tabular-only model.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
